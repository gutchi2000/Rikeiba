# keiba_web_app_minified_clean.py
# ç¸¦è»¸(WStd)ä¿®æ­£ï¼é‡è¤‡å‰Šé™¤ãƒã‚°ä¿®æ­£ï¼UIå¾©å…ƒï¼ˆè³¼å…¥åˆ¸ç¨®ãƒ©ã‚¸ã‚ªï¼‰ç‰ˆ
import streamlit as st
import pandas as pd
import numpy as np
import re, io, json
import matplotlib.pyplot as plt
from matplotlib import font_manager
from itertools import combinations

# Altair ã¯ä»»æ„
try:
    import altair as alt
    ALT_AVAILABLE = True
except Exception:
    ALT_AVAILABLE = False

@st.cache_resource
def get_jp_font():
    for path in ["ipaexg.ttf", "C:/Windows/Fonts/meiryo.ttc"]:
        try:
            return font_manager.FontProperties(fname=path)
        except Exception:
            pass
    return None

jp_font = get_jp_font()
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = ['IPAPGothic', 'Meiryo', 'MS Gothic']
st.set_page_config(page_title="ç«¶é¦¬äºˆæƒ³ã‚¢ãƒ—ãƒªï¼ˆè»½é‡ç‰ˆï¼‰", layout="wide")

def _inject_base_css():
    st.markdown("""
    <style>
    #MainMenu, header, footer {visibility:hidden;}
    section[data-testid="stSidebar"] {width: 340px !important;}
    div.block-container {padding-top: .8rem; padding-bottom: 1.5rem; max-width: 1400px;}
    button[role="tab"] {border-radius: 10px !important; padding: .35rem .8rem;}
    .smallcaps{font-variant:all-small-caps; opacity:.9}
    .badge{display:inline-block; padding:.2rem .5rem; border-radius:999px; background:#223; color:#cfe; font-size:.8rem; margin-right:.25rem}
    </style>
    """, unsafe_allow_html=True)
_inject_base_css()

with st.sidebar.expander("ğŸ§­ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ", expanded=True):
    st.markdown("""
1) **Excel**ï¼ˆsheet0=éå»èµ° / sheet1=å‡ºèµ°è¡¨ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰  
2) è¶³ã‚Šãªã„åˆ—ãŒã‚ã‚Œã° **åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°UI** ã‚’ON  
3) å·¦ã®ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’å°‘ã—èª¿æ•´ â†’ ä¸‹ã«**å‹ç‡**ãƒ»**ä¸Šä½é¦¬**ãƒ»**è²·ã„ç›®**ãŒå‡ºã¾ã™
""")

STYLES = ['é€ƒã’','å…ˆè¡Œ','å·®ã—','è¿½è¾¼']
_fwid = str.maketrans('ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼…','0123456789%')

# ===== util =====
def z_score(s: pd.Series) -> pd.Series:
    std = s.std(ddof=0)
    if std == 0 or pd.isna(std):
        return pd.Series([50]*len(s), index=s.index)
    return 50 + 10 * (s - s.mean()) / std

def season_of(m:int)->str:
    return 'æ˜¥' if 3<=m<=5 else 'å¤' if 6<=m<=8 else 'ç§‹' if 9<=m<=11 else 'å†¬'

def normalize_grade_text(x):
    if x is None or (isinstance(x,float) and np.isnan(x)): return None
    s = str(x).translate(_fwid)
    s = (s.replace('ï¼§','G').replace('ï¼ˆ','(').replace('ï¼‰',')')
           .replace('â… ','I').replace('â…¡','II').replace('â…¢','III'))
    s = re.sub(r'G\s*III','G3',s,flags=re.I); s = re.sub(r'G\s*II','G2',s,flags=re.I); s = re.sub(r'G\s*I','G1',s,flags=re.I)
    s = re.sub(r'ï¼ªï¼°ï¼®','Jpn',s,flags=re.I); s = re.sub(r'JPN','Jpn',s,flags=re.I)
    s = re.sub(r'Jpn\s*III','Jpn3',s,flags=re.I); s = re.sub(r'Jpn\s*II','Jpn2',s,flags=re.I); s = re.sub(r'Jpn\s*I','Jpn1',s,flags=re.I)
    m = re.search(r'(?:G|Jpn)\s*([123])',s,flags=re.I)
    return f"G{m.group(1)}" if m else None

@st.cache_data(show_spinner=False)
def load_excel_bytes(content: bytes):
    xls = pd.ExcelFile(io.BytesIO(content))
    return pd.read_excel(xls,0), pd.read_excel(xls,1)

def validate_inputs(df_score, horses):
    problems=[]
    for c in ['é¦¬å','ãƒ¬ãƒ¼ã‚¹æ—¥','ç«¶èµ°å','é ­æ•°','ç¢ºå®šç€é †']:
        if c not in df_score: problems.append(f"sheet0 å¿…é ˆåˆ—ãªã—: {c}")
    if 'æ–¤é‡' in horses:
        bad = horses['æ–¤é‡'].dropna()
        if len(bad)>0 and ((bad<45)|(bad>65)).any(): problems.append("sheet1 æ–¤é‡ãŒãƒ¬ãƒ³ã‚¸å¤–ï¼ˆ45â€“65ï¼‰")
    if {'é€šé4è§’','é ­æ•°'}.issubset(df_score.columns):
        tmp = df_score[['é€šé4è§’','é ­æ•°']].dropna()
        if len(tmp)>0 and ((tmp['é€šé4è§’']<1)|(tmp['é€šé4è§’']>tmp['é ­æ•°'])).any(): problems.append("sheet0 é€šé4è§’ãŒé ­æ•°ãƒ¬ãƒ³ã‚¸å¤–")
    if problems: st.warning("âš  å…¥åŠ›ãƒã‚§ãƒƒã‚¯ï¼š\n- "+"\n- ".join(problems))

def _parse_time_to_sec(x):
    if x is None or (isinstance(x,float) and np.isnan(x)): return np.nan
    s=str(x).strip()
    m=re.match(r'^(\d+):(\d+)\.(\d+)$',s)
    if m: return int(m.group(1))*60+int(m.group(2))+float('0.'+m.group(3))
    m=re.match(r'^(\d+)[\.:](\d+)[\.:](\d+)$',s)
    if m: return int(m.group(1))*60+int(m.group(2))+int(m.group(3))/10
    try: return float(s)
    except: return np.nan

def _norm_col(s:str)->str:
    s=str(s).strip(); s=re.sub(r'\s+','',s)
    s=s.translate(str.maketrans('ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™','0123456789')).replace('ï¼ˆ','(').replace('ï¼‰',')').replace('ï¼…','%')
    return s

def _auto_guess(col_map,pats):
    for orig,normed in col_map.items():
        for p in pats:
            if re.search(p,normed,flags=re.I): return orig
    return None

def _interactive_map(df, patterns, required_keys, title, state_key, show_ui=False):
    cols=list(df.columns); cmap={c:_norm_col(c) for c in cols}
    auto={k: st.session_state.get(f"{state_key}:{k}") or _auto_guess(cmap,pats) for k,pats in patterns.items()}
    if not show_ui:
        miss=[k for k in required_keys if not auto.get(k)]
        if not miss:
            for k,v in auto.items():
                if v: st.session_state[f"{state_key}:{k}"]=v
            return auto
        else:
            st.warning(f"{title} ã®å¿…é ˆåˆ—ãŒè‡ªå‹•èªè­˜ã§ãã¾ã›ã‚“: "+", ".join(miss))
            show_ui=True
    with st.expander(f"åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°ï¼š{title}", expanded=True):
        mapping={}
        for key,pats in patterns.items():
            default=st.session_state.get(f"{state_key}:{key}") or auto.get(key)
            mapping[key]=st.selectbox(key, ['<æœªé¸æŠ>']+cols,
                                      index=(['<æœªé¸æŠ>']+cols).index(default) if default in cols else 0,
                                      key=f"map:{state_key}:{key}")
            if mapping[key] != '<æœªé¸æŠ>': st.session_state[f"{state_key}:{key}"]=mapping[key]
    miss=[k for k in required_keys if mapping.get(k) in (None,'<æœªé¸æŠ>')]
    if miss: st.stop()
    return {k:(None if v=='<æœªé¸æŠ>' else v) for k,v in mapping.items()}

# ===== ã‚µã‚¤ãƒ‰ãƒãƒ¼ =====
st.sidebar.markdown("## âš™ï¸ ãƒ‘ãƒ©ãƒ¡ã‚¿è¨­å®š")
tab_basic, tab_detail = st.sidebar.tabs(["ğŸ”° ã‚ˆãä½¿ã†", "ğŸ›  è©³ç´°"])
with tab_basic:
    st.sidebar.header("åŸºæœ¬ã‚¹ã‚³ã‚¢ & ãƒœãƒ¼ãƒŠã‚¹")
    lambda_part  = st.sidebar.slider("å‡ºèµ°ãƒœãƒ¼ãƒŠã‚¹ Î»", 0.0, 1.0, 0.5, 0.05)
    besttime_w   = st.sidebar.slider("ãƒ™ã‚¹ãƒˆã‚¿ã‚¤ãƒ é‡ã¿", 0.0, 2.0, 1.0)
    with st.sidebar.expander("æˆ¦ç¸¾ç‡ã®é‡ã¿ï¼ˆå½“è©²é¦¬å ´ï¼‰", expanded=False):
        win_w  = st.slider("å‹ç‡ã®é‡ã¿",0.0,5.0,1.0,0.1,key="w_win")
        quin_w = st.slider("é€£å¯¾ç‡ã®é‡ã¿",0.0,5.0,0.7,0.1,key="w_quin")
        plc_w  = st.slider("è¤‡å‹ç‡ã®é‡ã¿",0.0,5.0,0.5,0.1,key="w_plc")
    with st.sidebar.expander("å„ç¨®ãƒœãƒ¼ãƒŠã‚¹è¨­å®š", expanded=False):
        grade_bonus  = st.slider("é‡è³å®Ÿç¸¾ãƒœãƒ¼ãƒŠã‚¹",0,20,5)
        agari1_bonus = st.slider("ä¸ŠãŒã‚Š3F 1ä½ãƒœãƒ¼ãƒŠã‚¹",0,10,3)
        agari2_bonus = st.slider("ä¸ŠãŒã‚Š3F 2ä½ãƒœãƒ¼ãƒŠã‚¹",0,5,2)
        agari3_bonus = st.slider("ä¸ŠãŒã‚Š3F 3ä½ãƒœãƒ¼ãƒŠã‚¹",0,3,1)
        bw_bonus     = st.slider("é¦¬ä½“é‡é©æ­£ãƒœãƒ¼ãƒŠã‚¹(Â±10kg)",0,10,2)
    with st.sidebar.expander("æœ¬ãƒ¬ãƒ¼ã‚¹æ¡ä»¶ï¼ˆãƒ™ã‚¹ãƒˆã‚¿ã‚¤ãƒ é‡ã¿ç”¨ï¼‰", expanded=True):
        TARGET_GRADE = st.selectbox("æœ¬ãƒ¬ãƒ¼ã‚¹ã®æ ¼", ["G1","G2","G3","L","OP"], index=4, key="target_grade")
        TARGET_SURFACE = st.selectbox("æœ¬ãƒ¬ãƒ¼ã‚¹ã®é¦¬å ´", ["èŠ","ãƒ€"], index=0, key="target_surface")
        TARGET_DISTANCE_M = st.number_input("æœ¬ãƒ¬ãƒ¼ã‚¹ã®è·é›¢ [m]", 1000, 3600, 1800, 100, key="target_distance_m")
    st.sidebar.markdown("---")
    st.sidebar.header("æ™‚ç³»åˆ—ãƒ»å®‰å®šæ€§ãƒ»è£œæ­£")
    half_life_m  = st.sidebar.slider("æ™‚ç³»åˆ—åŠæ¸›æœŸ(æœˆ)", 0.0, 12.0, 6.0, 0.5)
    stab_weight  = st.sidebar.slider("å®‰å®šæ€§(å°ã•ã„ã»ã©â—)ã®ä¿‚æ•°", 0.0, 2.0, 0.7, 0.1)
    pace_gain    = st.sidebar.slider("ãƒšãƒ¼ã‚¹é©æ€§ä¿‚æ•°", 0.0, 3.0, 1.0, 0.1)
    weight_coeff = st.sidebar.slider("æ–¤é‡ãƒšãƒŠãƒ«ãƒ†ã‚£å¼·åº¦(pts/kg)", 0.0, 4.0, 1.0, 0.1)
    with st.sidebar.expander("æ–¤é‡ãƒ™ãƒ¼ã‚¹ï¼ˆWFA/JRAç°¡ç•¥ï¼‰", expanded=False):
        race_date = pd.to_datetime(st.date_input("é–‹å‚¬æ—¥", value=pd.Timestamp.today().date()))
        use_wfa_base = st.checkbox("WFAåŸºæº–ã‚’ä½¿ã†ï¼ˆæ¨å¥¨ï¼‰", value=True)
        wfa_2_early_m = st.number_input("2æ­³ï¼ˆã€œ9æœˆï¼‰ ç‰¡/ã›ã‚“ [kg]", 50.0, 60.0, 55.0, 0.5)
        wfa_2_early_f = st.number_input("2æ­³ï¼ˆã€œ9æœˆï¼‰ ç‰ [kg]"    , 48.0, 60.0, 54.0, 0.5)
        wfa_2_late_m  = st.number_input("2æ­³ï¼ˆ10-12æœˆï¼‰ ç‰¡/ã›ã‚“ [kg]", 50.0, 60.0, 56.0, 0.5)
        wfa_2_late_f  = st.number_input("2æ­³ï¼ˆ10-12æœˆï¼‰ ç‰ [kg]"    , 48.0, 60.0, 55.0, 0.5)
        wfa_3p_m      = st.number_input("3æ­³ä»¥ä¸Š ç‰¡/ã›ã‚“ [kg]" , 50.0, 62.0, 57.0, 0.5)
        wfa_3p_f      = st.number_input("3æ­³ä»¥ä¸Š ç‰ [kg]"     , 48.0, 60.0, 55.0, 0.5)
    st.sidebar.markdown("---")
    st.sidebar.header("è³‡é‡‘ãƒ»ç‚¹æ•°ï¼ˆè³¼å…¥æˆ¦ç•¥ï¼‰")
    total_budget = st.sidebar.slider("åˆè¨ˆäºˆç®—", 500, 50000, 10000, 100)
    min_unit     = st.sidebar.selectbox("æœ€å°è³­ã‘å˜ä½", [100,200,300,500], index=0)
    max_lines    = st.sidebar.slider("æœ€å¤§ç‚¹æ•°(é€£ç³»)", 1, 60, 20, 1)
    scenario     = st.sidebar.selectbox("ã‚·ãƒŠãƒªã‚ª", ['é€šå¸¸','ã¡ã‚‡ã„ä½™è£•','ä½™è£•'])
    show_map_ui  = st.sidebar.checkbox("åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°UIã‚’è¡¨ç¤º", value=False)

with tab_detail:
    st.sidebar.header("å±æ€§é‡ã¿ï¼ˆ1èµ°ã‚¹ã‚³ã‚¢ä¿‚æ•°ï¼‰")
    gender_w = {g: st.slider(f"{g}", 0.0, 2.0, 1.0) for g in ['ç‰¡','ç‰','ã‚»']}
    style_w  = {s: st.slider(f"{s}", 0.0, 2.0, 1.0) for s in STYLES}
    season_w = {s: st.slider(f"{s}", 0.0, 2.0, 1.0) for s in ['æ˜¥','å¤','ç§‹','å†¬']}
    age_w    = {str(a): st.slider(f"{a}æ­³", 0.0, 2.0, 1.0, 0.05) for a in range(3,11)}
    frame_w  = {str(i): st.slider(f"{i}æ ", 0.0, 2.0, 1.0) for i in range(1,9)}
    st.sidebar.markdown("---")
    st.sidebar.header("ãƒšãƒ¼ã‚¹ / è„šè³ª")
    with st.sidebar.expander("è„šè³ªè‡ªå‹•æ¨å®šï¼ˆå¼·åŒ–ï¼‰", expanded=False):
        auto_style_on   = st.checkbox("è‡ªå‹•æ¨å®šã‚’ä½¿ã†", True)
        AUTO_OVERWRITE  = st.checkbox("æ‰‹å…¥åŠ›ã‚ˆã‚Šè‡ªå‹•ã‚’å„ªå…ˆ", False)
        NRECENT         = st.slider("ç›´è¿‘ãƒ¬ãƒ¼ã‚¹æ•°", 1, 10, 5)
        HL_DAYS_STYLE   = st.slider("åŠæ¸›æœŸï¼ˆæ—¥ãƒ»è„šè³ªï¼‰", 30, 365, 180, 15)
        pace_mc_draws   = st.slider("ãƒšãƒ¼ã‚¹MCå›æ•°", 500, 30000, 5000, 500)
    with st.sidebar.expander("ãƒšãƒ¼ã‚¹è¨­å®šï¼ˆè‡ªå‹•MC / å›ºå®šï¼‰", expanded=False):
        pace_mode = st.radio("ãƒšãƒ¼ã‚¹ã®æ‰±ã„", ["è‡ªå‹•ï¼ˆMCï¼‰","å›ºå®šï¼ˆæ‰‹å‹•ï¼‰"], index=0)
        pace_fixed = st.selectbox("å›ºå®šãƒšãƒ¼ã‚¹", ["ãƒã‚¤ãƒšãƒ¼ã‚¹","ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹","ã‚„ã‚„ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹","ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹"],
                                  1, disabled=(pace_mode=="è‡ªå‹•ï¼ˆMCï¼‰"))
    with st.sidebar.expander("EPIï¼ˆå‰åœ§ï¼‰ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°", expanded=False):
        epi_alpha = st.slider("é€ƒã’ä¿‚æ•° Î±", 0.0, 2.0, 1.0, 0.05)
        epi_beta  = st.slider("å…ˆè¡Œä¿‚æ•° Î²", 0.0, 2.0, 0.60, 0.05)
        thr_hi    = st.slider("é–¾å€¤: ãƒã‚¤ãƒšãƒ¼ã‚¹ â‰¥", 0.30, 1.00, 0.52, 0.01)
        thr_mid   = st.slider("é–¾å€¤: ãƒŸãƒ‰ãƒ« â‰¥",    0.10, 0.99, 0.30, 0.01)
        thr_slow  = st.slider("é–¾å€¤: ã‚„ã‚„ã‚¹ãƒ­ãƒ¼ â‰¥",0.00, 0.98, 0.18, 0.01)
    st.sidebar.markdown("---")
    st.sidebar.header("å‹ç‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ï¼‰")
    with st.sidebar.expander("è©³ç´°è¨­å®š", expanded=False):
        mc_iters   = st.slider("åå¾©å›æ•°", 1000, 100000, 20000, 1000)
        mc_beta    = st.slider("æ¸©åº¦Î²", 0.1, 5.0, 1.5, 0.1)
        mc_tau     = st.slider("å®‰å®šåº¦ãƒã‚¤ã‚º Ï„", 0.0, 2.0, 0.6, 0.05)
        mc_seed    = st.number_input("ä¹±æ•°Seed", 0, 999999, 42, 1)
    with st.sidebar.expander("ãã®ä»–ï¼ˆé–‹ç™ºè€…å‘ã‘ï¼‰", expanded=False):
        orig_weight  = st.slider("OrigZ ã®é‡ã¿ (æœªä½¿ç”¨)", 0.0, 1.0, 0.5, 0.05)

# ===== ãƒ•ã‚¡ã‚¤ãƒ« =====
st.title("ç«¶é¦¬äºˆæƒ³ã‚¢ãƒ—ãƒªï¼ˆè»½é‡ç‰ˆãƒ»äº’æ›æ€§å¼·åŒ–ï¼‰")
st.subheader("ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
excel_file = st.file_uploader("Excelï¼ˆsheet0=éå»èµ° / sheet1=å‡ºèµ°è¡¨ï¼‰", type=['xlsx'], key="excel_up")
if excel_file is None:
    st.info("ã¾ãšExcelï¼ˆ.xlsxï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"); st.stop()
sheet0, sheet1 = load_excel_bytes(excel_file.getvalue())

# === sheet0 ===
PAT_S0 = {
    'é¦¬å':[r'é¦¬å|åå‰|å‡ºèµ°é¦¬'],'ãƒ¬ãƒ¼ã‚¹æ—¥':[r'ãƒ¬ãƒ¼ã‚¹æ—¥|æ—¥ä»˜S|æ—¥ä»˜|å¹´æœˆæ—¥'],
    'ç«¶èµ°å':[r'ç«¶èµ°å|ãƒ¬ãƒ¼ã‚¹å|åç§°'],'ã‚¯ãƒ©ã‚¹å':[r'ã‚¯ãƒ©ã‚¹å|æ ¼|æ¡ä»¶|ãƒ¬ãƒ¼ã‚¹ã‚°ãƒ¬ãƒ¼ãƒ‰'],
    'é ­æ•°':[r'é ­æ•°|å‡ºèµ°é ­æ•°'],'ç¢ºå®šç€é †':[r'ç¢ºå®šç€é †|ç€é †(?!ç‡)'],
    'æ ':[r'æ |æ ç•ª'],'ç•ª':[r'é¦¬ç•ª|ç•ª'],'æ–¤é‡':[r'æ–¤é‡'],'é¦¬ä½“é‡':[r'é¦¬ä½“é‡|ä½“é‡'],
    'ä¸ŠãŒã‚Š3Fã‚¿ã‚¤ãƒ ':[r'ä¸ŠãŒã‚Š3Fã‚¿ã‚¤ãƒ |ä¸ŠãŒã‚Š3F|ä¸Š3Fã‚¿ã‚¤ãƒ |ä¸Š3F'],'ä¸Š3Fé †ä½':[r'ä¸ŠãŒã‚Š3Fé †ä½|ä¸Š3Fé †ä½'],
    'é€šé4è§’':[r'é€šé.*4è§’|4è§’.*é€šé|ç¬¬4ã‚³ãƒ¼ãƒŠãƒ¼é †ä½|4è§’é †ä½'],'æ€§åˆ¥':[r'æ€§åˆ¥'],'å¹´é½¢':[r'å¹´é½¢|é¦¬é½¢'],
    'èµ°ç ´ã‚¿ã‚¤ãƒ ç§’':[r'èµ°ç ´ã‚¿ã‚¤ãƒ .*ç§’|èµ°ç ´ã‚¿ã‚¤ãƒ |ã‚¿ã‚¤ãƒ $'],'è·é›¢':[r'è·é›¢'],'é¦¬å ´':[r'é¦¬å ´|é¦¬å ´çŠ¶æ…‹'],'å¤©å€™':[r'å¤©å€™'],
}
REQ_S0 = ['é¦¬å','ãƒ¬ãƒ¼ã‚¹æ—¥','ç«¶èµ°å','é ­æ•°','ç¢ºå®šç€é †']
MAP_S0 = _interactive_map(sheet0, PAT_S0, REQ_S0, "sheet0ï¼ˆéå»èµ°ï¼‰", "s0", show_ui=show_map_ui)

df_score = pd.DataFrame()
for k, col in MAP_S0.items():
    if col is None: continue
    df_score[k] = sheet0[col]

df_score['ãƒ¬ãƒ¼ã‚¹æ—¥'] = pd.to_datetime(df_score['ãƒ¬ãƒ¼ã‚¹æ—¥'], errors='coerce')
for c in ['é ­æ•°','ç¢ºå®šç€é †','æ ','ç•ª','æ–¤é‡','é¦¬ä½“é‡','ä¸Š3Fé †ä½','é€šé4è§’','è·é›¢']:
    if c in df_score: df_score[c] = pd.to_numeric(df_score[c], errors='coerce')
if 'èµ°ç ´ã‚¿ã‚¤ãƒ ç§’' in df_score: df_score['èµ°ç ´ã‚¿ã‚¤ãƒ ç§’'] = df_score['èµ°ç ´ã‚¿ã‚¤ãƒ ç§’'].apply(_parse_time_to_sec)
if 'ä¸ŠãŒã‚Š3Fã‚¿ã‚¤ãƒ ' in df_score: df_score['ä¸ŠãŒã‚Š3Fã‚¿ã‚¤ãƒ '] = df_score['ä¸ŠãŒã‚Š3Fã‚¿ã‚¤ãƒ '].apply(_parse_time_to_sec)

if 'é ­æ•°' in df_score:
    df_score['é ­æ•°'] = df_score['é ­æ•°'].astype(str).str.extract(r'(\d+)')[0].apply(pd.to_numeric, errors='coerce')
if 'é€šé4è§’' in df_score:
    s = df_score['é€šé4è§’']
    if s.dtype.kind not in 'iu':
        last_num = s.astype(str).str.extract(r'(\d+)(?!.*\d)')[0]
        df_score['é€šé4è§’'] = pd.to_numeric(last_num, errors='coerce')
    ok = df_score['é ­æ•°'].notna() & df_score['é€šé4è§’'].notna()
    bad = ok & ((df_score['é€šé4è§’'] < 1) | (df_score['é€šé4è§’'] > df_score['é ­æ•°']))
    df_score.loc[df_score['é€šé4è§’'].eq(0), 'é€šé4è§’'] = np.nan
    df_score.loc[bad, 'é€šé4è§’'] = np.nan

# === sheet1 ===
PAT_S1 = {
    'é¦¬å':[r'é¦¬å|åå‰|å‡ºèµ°é¦¬'],'æ ':[r'æ |æ ç•ª'],'ç•ª':[r'é¦¬ç•ª|ç•ª'],'æ€§åˆ¥':[r'æ€§åˆ¥'],'å¹´é½¢':[r'å¹´é½¢|é¦¬é½¢'],
    'æ–¤é‡':[r'æ–¤é‡'],'é¦¬ä½“é‡':[r'é¦¬ä½“é‡|ä½“é‡'],'è„šè³ª':[r'è„šè³ª'],
    'å‹ç‡':[r'å‹ç‡(?!.*ç‡)|\bå‹ç‡\b'],'é€£å¯¾ç‡':[r'é€£å¯¾ç‡|é€£å¯¾'],'è¤‡å‹ç‡':[r'è¤‡å‹ç‡|è¤‡å‹'],
    'ãƒ™ã‚¹ãƒˆã‚¿ã‚¤ãƒ ':[r'ãƒ™ã‚¹ãƒˆ.*ã‚¿ã‚¤ãƒ |Best.*Time|ï¾ï¾ï½½ï¾„.*ï¾€ï½²ï¾‘|ã‚¿ã‚¤ãƒ .*(æœ€é€Ÿ|ãƒ™ã‚¹ãƒˆ)'],
}
REQ_S1 = ['é¦¬å','æ ','ç•ª','æ€§åˆ¥','å¹´é½¢']
MAP_S1 = _interactive_map(sheet1, PAT_S1, REQ_S1, "sheet1ï¼ˆå‡ºèµ°è¡¨ï¼‰", "s1", show_ui=show_map_ui)

attrs = pd.DataFrame()
for k, col in MAP_S1.items():
    if col is None: continue
    attrs[k] = sheet1[col]
for c in ['æ ','ç•ª','æ–¤é‡','é¦¬ä½“é‡']:
    if c in attrs: attrs[c] = pd.to_numeric(attrs[c], errors='coerce')
if 'ãƒ™ã‚¹ãƒˆã‚¿ã‚¤ãƒ ' in attrs: attrs['ãƒ™ã‚¹ãƒˆã‚¿ã‚¤ãƒ ç§’'] = attrs['ãƒ™ã‚¹ãƒˆã‚¿ã‚¤ãƒ '].apply(_parse_time_to_sec)

# å…¥åŠ›UI
if 'è„šè³ª' not in attrs: attrs['è„šè³ª'] = ''
if 'æ–¤é‡' not in attrs: attrs['æ–¤é‡'] = np.nan
if 'é¦¬ä½“é‡' not in attrs: attrs['é¦¬ä½“é‡'] = np.nan

st.subheader("é¦¬ä¸€è¦§ãƒ»è„šè³ªãƒ»æ–¤é‡ãƒ»å½“æ—¥é¦¬ä½“é‡å…¥åŠ›")
edited = st.data_editor(
    attrs[['æ ','ç•ª','é¦¬å','æ€§åˆ¥','å¹´é½¢','è„šè³ª','æ–¤é‡','é¦¬ä½“é‡']].copy(),
    column_config={
        'è„šè³ª': st.column_config.SelectboxColumn('è„šè³ª', options=STYLES),
        'æ–¤é‡': st.column_config.NumberColumn('æ–¤é‡', min_value=45, max_value=65, step=0.5),
        'é¦¬ä½“é‡': st.column_config.NumberColumn('é¦¬ä½“é‡', min_value=300, max_value=600, step=1)
    },
    use_container_width=True, num_rows='static'
)
horses = edited.copy()
validate_inputs(df_score, horses)

# --- è„šè³ªè‡ªå‹•æ¨å®šï¼ˆçœç•¥ï¼šå…ƒã‚³ãƒ¼ãƒ‰ã¨åŒã˜ï¼‰ ---
df_style = pd.DataFrame({'é¦¬å': [], 'p_é€ƒã’': [], 'p_å…ˆè¡Œ': [], 'p_å·®ã—': [], 'p_è¿½è¾¼': [], 'æ¨å®šè„šè³ª': []})
need_cols = {'é¦¬å','ãƒ¬ãƒ¼ã‚¹æ—¥','é ­æ•°','é€šé4è§’'}
if auto_style_on and need_cols.issubset(df_score.columns):
    tmp = (df_score[['é¦¬å','ãƒ¬ãƒ¼ã‚¹æ—¥','é ­æ•°','é€šé4è§’','ä¸Š3Fé †ä½']].copy()
            .dropna(subset=['é¦¬å','ãƒ¬ãƒ¼ã‚¹æ—¥','é ­æ•°','é€šé4è§’'])
            .sort_values(['é¦¬å','ãƒ¬ãƒ¼ã‚¹æ—¥'], ascending=[True, False]))
    tmp['_rn'] = tmp.groupby('é¦¬å').cumcount()+1
    tmp = tmp[tmp['_rn'] <= int(NRECENT)].copy()
    today = pd.Timestamp.today()
    tmp['_days'] = (today - pd.to_datetime(tmp['ãƒ¬ãƒ¼ã‚¹æ—¥'], errors='coerce')).dt.days.clip(lower=0).fillna(9999)
    tmp['_w'] = 0.5 ** (tmp['_days'] / float(HL_DAYS_STYLE))
    denom = (pd.to_numeric(tmp['é ­æ•°'], errors='coerce') - 1).replace(0, np.nan)
    pos_ratio = (pd.to_numeric(tmp['é€šé4è§’'], errors='coerce') - 1) / denom
    pos_ratio = pos_ratio.clip(0, 1).fillna(0.5)
    if 'ä¸Š3Fé †ä½' in tmp.columns:
        ag = pd.to_numeric(tmp['ä¸Š3Fé †ä½'], errors='coerce')
        close_strength = ((3.5 - ag) / 3.5).clip(0,1).fillna(0.0)
    else:
        close_strength = pd.Series(0.0, index=tmp.index)
    b_nige,b_sengo,b_sashi,b_oikomi = -1.2,0.6,0.3,-0.7
    tmp['L_nige']= b_nige+1.6*(1-pos_ratio)-1.2*close_strength
    tmp['L_sengo']=b_sengo+1.1*(1-pos_ratio)-0.1*close_strength
    tmp['L_sashi']=b_sashi+1.1*(pos_ratio)+0.9*close_strength
    tmp['L_oikomi']=b_oikomi+1.6*(pos_ratio)+0.5*close_strength
    rows=[]
    for name,g in tmp.groupby('é¦¬å'):
        w=g['_w'].to_numpy(); sw=w.sum()
        if sw<=0: continue
        wavg=lambda v: float((v*w).sum()/sw)
        vec=np.array([wavg(g['L_nige']),wavg(g['L_sengo']),wavg(g['L_sashi']),wavg(g['L_oikomi'])],dtype=float)
        vec=vec-vec.max(); p=np.exp(vec); p=p/p.sum(); pred=STYLES[int(np.argmax(p))]
        pr=(pd.to_numeric(g['é€šé4è§’'],errors='coerce')-1)/(pd.to_numeric(g['é ­æ•°'],errors='coerce')-1)
        pr=pr.clip(0,1).fillna(0.5); wpr=float((pr*w).sum()/sw)
        if pred=='é€ƒã’' and not (wpr<=0.22 or ((pr<=0.15)*w).sum()/sw>=0.25): pred='å…ˆè¡Œ'
        if pred=='è¿½è¾¼' and not (wpr>=0.78 or ((pr>=0.85)*w).sum()/sw>=0.25): pred='å·®ã—'
        rows.append([name,*p.tolist(),pred])
    if rows:
        df_style=pd.DataFrame(rows,columns=['é¦¬å','p_é€ƒã’','p_å…ˆè¡Œ','p_å·®ã—','p_è¿½è¾¼','æ¨å®šè„šè³ª'])

# --- æˆ¦ç¸¾ç‡(%â†’æ•°å€¤)ï¼†ãƒ™ã‚¹ãƒˆã‚¿ã‚¤ãƒ  ---
rate_cols=[c for c in ['å‹ç‡','é€£å¯¾ç‡','è¤‡å‹ç‡'] if c in attrs.columns]
if rate_cols:
    rate = attrs[['é¦¬å']+rate_cols].copy()
    for c in rate_cols:
        rate[c]=rate[c].astype(str).str.replace('%','',regex=False).str.replace('ï¼…','',regex=False)
        rate[c]=pd.to_numeric(rate[c], errors='coerce')
    mx = pd.concat([rate[c] for c in rate_cols], axis=1).max().max()
    if pd.notna(mx) and mx <= 1.0:
        for c in rate_cols: rate[c]*=100.0
    if 'ãƒ™ã‚¹ãƒˆã‚¿ã‚¤ãƒ ç§’' in attrs: rate=rate.merge(attrs[['é¦¬å','ãƒ™ã‚¹ãƒˆã‚¿ã‚¤ãƒ ç§’']], on='é¦¬å', how='left')
else:
    rate=pd.DataFrame({'é¦¬å':[],'å‹ç‡':[],'é€£å¯¾ç‡':[],'è¤‡å‹ç‡':[],'ãƒ™ã‚¹ãƒˆã‚¿ã‚¤ãƒ ç§’':[]})

# === é‡è¤‡ã‚¬ãƒ¼ãƒ‰ï¼ˆâ†ã“ã“ãŒãƒã‚°ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆï¼‰ ===
try:
    if 'é¦¬å' in horses.columns:
        horses.drop_duplicates('é¦¬å', keep='first', inplace=True)   # horsesã®ã¿
except Exception: pass
try:
    df_score = df_score.drop_duplicates(subset=['é¦¬å','ãƒ¬ãƒ¼ã‚¹æ—¥','ç«¶èµ°å'], keep='first')  # éå»èµ°ã¯å®Œå…¨é‡è¤‡ã®ã¿é™¤å»
except Exception: pass

# ===== ãƒãƒ¼ã‚¸ =====
for dup in ['æ ','ç•ª','æ€§åˆ¥','å¹´é½¢','æ–¤é‡','é¦¬ä½“é‡','è„šè³ª']:
    df_score.drop(columns=[dup], errors='ignore', inplace=True)
df_score = df_score.merge(horses[['é¦¬å','æ ','ç•ª','æ€§åˆ¥','å¹´é½¢','æ–¤é‡','é¦¬ä½“é‡','è„šè³ª']], on='é¦¬å', how='left')
if len(rate)>0:
    use_cols=['é¦¬å']+[c for c in ['å‹ç‡','é€£å¯¾ç‡','è¤‡å‹ç‡','ãƒ™ã‚¹ãƒˆã‚¿ã‚¤ãƒ ç§’'] if c in rate.columns]
    df_score=df_score.merge(rate[use_cols], on='é¦¬å', how='left')

# ===== ãƒ™ã‚¹ãƒˆã‚¿ã‚¤ãƒ é‡ã¿ =====
bt_min = df_score['ãƒ™ã‚¹ãƒˆã‚¿ã‚¤ãƒ ç§’'].min(skipna=True) if 'ãƒ™ã‚¹ãƒˆã‚¿ã‚¤ãƒ ç§’' in df_score else np.nan
bt_max = df_score['ãƒ™ã‚¹ãƒˆã‚¿ã‚¤ãƒ ç§’'].max(skipna=True) if 'ãƒ™ã‚¹ãƒˆã‚¿ã‚¤ãƒ ç§’' in df_score else np.nan
bt_span = (bt_max-bt_min) if pd.notna(bt_min) and pd.notna(bt_max) and (bt_max>bt_min) else 1.0
CLASS_BASE_BT={"OP":1.50,"L":1.38,"G3":1.19,"G2":1.00,"G1":0.80}
def besttime_weight_final(grade,surface,distance_m,user_scale):
    base=CLASS_BASE_BT.get(str(grade),CLASS_BASE_BT["OP"])
    s=1.10 if str(surface)=="ãƒ€" else 1.00
    try:
        d=int(distance_m)
        if d<=1400: dfac=1.20
        elif d==1600: dfac=1.10
        elif 1800<=d<=2200: dfac=1.00
        elif d>=2400: dfac=0.85
        else: dfac=1.00
    except: dfac=1.00
    return float(np.clip(base*s*dfac*float(user_scale),0.0,2.0))

CLASS_PTS={'G1':10,'G2':8,'G3':6,'ãƒªã‚¹ãƒ†ãƒƒãƒ‰':5,'ã‚ªãƒ¼ãƒ—ãƒ³ç‰¹åˆ¥':4}
def class_points(row)->int:
    g=normalize_grade_text(row.get('ã‚¯ãƒ©ã‚¹å')) if 'ã‚¯ãƒ©ã‚¹å' in row else None
    if not g and 'ç«¶èµ°å' in row: g=normalize_grade_text(row.get('ç«¶èµ°å'))
    if g in CLASS_PTS: return CLASS_PTS[g]
    name=str(row.get('ã‚¯ãƒ©ã‚¹å',''))+' '+str(row.get('ç«¶èµ°å',''))
    if re.search(r'3\s*å‹',name): return 3
    if re.search(r'2\s*å‹',name): return 2
    if re.search(r'1\s*å‹',name): return 1
    if re.search(r'æ–°é¦¬|æœªå‹åˆ©',name): return 1
    if re.search(r'ã‚ªãƒ¼ãƒ—ãƒ³',name): return 4
    if re.search(r'ãƒªã‚¹ãƒ†ãƒƒãƒ‰|L\b',name,flags=re.I): return 5
    return 1

def wfa_base_for(sex:str, age, dt:pd.Timestamp)->float:
    try: a=int(age) if age is not None and not pd.isna(age) else None
    except: a=None
    m=int(dt.month) if isinstance(dt,pd.Timestamp) else 1
    if a==2:
        male = wfa_2_early_m if m<=9 else wfa_2_late_m
        filly= wfa_2_early_f if m<=9 else wfa_2_late_f
    elif a is not None and a>=3:
        male,filly=wfa_3p_m,wfa_3p_f
    else:
        male,filly=wfa_3p_m,wfa_3p_f
    return male if sex in ("ç‰¡","ã‚»") else filly

def calc_score(r):
    g = class_points(r)
    raw = g*(r['é ­æ•°']+1-r['ç¢ºå®šç€é †']) + lambda_part*g
    sw  = season_w[season_of(pd.to_datetime(r['ãƒ¬ãƒ¼ã‚¹æ—¥']).month)]
    gw  = gender_w.get(r.get('æ€§åˆ¥'),1)
    stw = style_w.get(r.get('è„šè³ª'),1)
    fw  = frame_w.get(str(r.get('æ ')),1)
    aw  = age_w.get(str(r.get('å¹´é½¢')),1.0)
    gnorm = normalize_grade_text(r.get('ã‚¯ãƒ©ã‚¹å'))
    grade_point = grade_bonus if gnorm in ['G1','G2','G3'] else 0
    agari_bonus=0
    try:
        ao=int(r.get('ä¸Š3Fé †ä½',np.nan))
        if ao==1: agari_bonus=agari1_bonus
        elif ao==2: agari_bonus=agari2_bonus
        elif ao==3: agari_bonus=agari3_bonus
    except: pass
    rate_bonus=0.0
    try:
        if 'å‹ç‡' in r and pd.notna(r.get('å‹ç‡',np.nan)):   rate_bonus+=win_w  * (float(r['å‹ç‡'])/100.0)
        if 'é€£å¯¾ç‡' in r and pd.notna(r.get('é€£å¯¾ç‡',np.nan)): rate_bonus+=quin_w * (float(r['é€£å¯¾ç‡'])/100.0)
        if 'è¤‡å‹ç‡' in r and pd.notna(r.get('è¤‡å‹ç‡',np.nan)): rate_bonus+=plc_w  * (float(r['è¤‡å‹ç‡'])/100.0)
    except: pass
    bt_bonus=0.0
    try:
        if pd.notna(r.get('ãƒ™ã‚¹ãƒˆã‚¿ã‚¤ãƒ ç§’',np.nan)):
            bt_norm=(bt_max-float(r['ãƒ™ã‚¹ãƒˆã‚¿ã‚¤ãƒ ç§’']))/bt_span
            bt_norm=max(0.0,min(1.0,bt_norm))
            bt_bonus = besttime_weight_final(st.session_state.get("target_grade",TARGET_GRADE),
                                             st.session_state.get("target_surface",TARGET_SURFACE),
                                             int(st.session_state.get("target_distance_m",TARGET_DISTANCE_M)),
                                             besttime_w) * bt_norm
    except: pass
    kg_pen=0.0
    try:
        kg=float(r.get('æ–¤é‡',np.nan))
        if not np.isnan(kg):
            base = wfa_base_for(str(r.get('æ€§åˆ¥','')), int(r.get('å¹´é½¢',3)), race_date) if use_wfa_base else 56.0
            delta=kg-float(base)
            kg_pen = (-max(0.0,delta)*float(weight_coeff) + 0.5*max(0.0,-delta)*float(weight_coeff))
    except: pass
    return raw*sw*gw*stw*fw*aw + (grade_point+agari_bonus+rate_bonus+bt_bonus+kg_pen)

if 'ãƒ¬ãƒ¼ã‚¹æ—¥' not in df_score:
    st.error("ãƒ¬ãƒ¼ã‚¹æ—¥ åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"); st.stop()
df_score['score_raw']=df_score.apply(calc_score, axis=1)
if df_score['score_raw'].max()==df_score['score_raw'].min():
    df_score['score_norm']=50.0
else:
    rng=(df_score['score_raw']-df_score['score_raw'].min())/(df_score['score_raw'].max()-df_score['score_raw'].min())
    df_score['score_norm']=rng*100

# ===== æ™‚ç³»åˆ—åŠ é‡ & ä¸ååŠ é‡æ¨™æº–åå·® =====
now=pd.Timestamp.today()
df_score['_days_ago']=(now-df_score['ãƒ¬ãƒ¼ã‚¹æ—¥']).dt.days
df_score['_w']=0.5 ** (df_score['_days_ago']/(half_life_m*30.4375)) if half_life_m>0 else 1.0

def w_mean(x,w):
    w=np.asarray(w,dtype=float); x=np.asarray(x,dtype=float); s=w.sum()
    return float((x*w).sum()/s) if s>0 else np.nan

def w_std(x,w,ddof=1):
    w=np.asarray(w,dtype=float); x=np.asarray(x,dtype=float); s=w.sum()
    if s<=0: return np.nan
    m=(x*w).sum()/s
    num=(w*((x-m)**2)).sum()
    if ddof==0:
        denom=s
    else:
        w2=(w**2).sum()
        denom=s - w2/s  # ä¸åï¼ˆé »åº¦é‡ã¿ï¼‰
        if denom<=0: denom=s
    return float(np.sqrt(num/denom))

agg=[]
for name,g in df_score.groupby('é¦¬å'):
    avg=g['score_norm'].mean()
    std=g['score_norm'].std(ddof=0)
    wavg=w_mean(g['score_norm'], g['_w'])
    wstd=w_std(g['score_norm'], g['_w'], ddof=1)
    agg.append({'é¦¬å':name,'AvgZ':avg,'Stdev':std,'WAvgZ':wavg,'WStd':wstd})
df_agg=pd.DataFrame(agg)
for c in ['Stdev','WStd']:
    if c in df_agg: df_agg[c]=df_agg[c].fillna(df_agg[c].median())

df_agg['RecencyZ']=z_score(df_agg['WAvgZ'])
df_agg['StabZ']=z_score(-df_agg['WStd'].fillna(df_agg['WStd'].median()))

# è„šè³ªçµ±åˆ
def _trim_name(x): 
    try: return str(x).replace('\u3000',' ').strip()
    except: return x
for df in [horses,df_agg]:
    if 'é¦¬å' in df: df['é¦¬å']=df['é¦¬å'].map(_trim_name)

combined_style=pd.Series(index=df_agg['é¦¬å'], dtype=object)
if 'è„šè³ª' in horses.columns:
    combined_style.update(horses.set_index('é¦¬å')['è„šè³ª'])
if not df_style.empty and auto_style_on:
    pred_series=df_style.set_index('é¦¬å')['æ¨å®šè„šè³ª'].reindex(combined_style.index)
    mask=combined_style.isna()|combined_style.astype(str).str.strip().eq('')
    combined_style.loc[mask]=pred_series.loc[mask]
combined_style=combined_style.fillna('')
df_agg['è„šè³ª']=df_agg['é¦¬å'].map(combined_style)

# ãƒšãƒ¼ã‚¹æƒ³å®š
H=len(df_agg)
P=np.zeros((H,4),dtype=float)
for i,nm in enumerate(df_agg['é¦¬å']):
    stl=combined_style.get(nm,'')
    if stl in STYLES:
        P[i, STYLES.index(stl)]=1.0
    else:
        P[i,:]=0.25
mark_rule={
    'ãƒã‚¤ãƒšãƒ¼ã‚¹':{'é€ƒã’':'â–³','å…ˆè¡Œ':'â–³','å·®ã—':'â—','è¿½è¾¼':'ã€‡'},
    'ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹':{'é€ƒã’':'ã€‡','å…ˆè¡Œ':'â—','å·®ã—':'ã€‡','è¿½è¾¼':'â–³'},
    'ã‚„ã‚„ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹':{'é€ƒã’':'ã€‡','å…ˆè¡Œ':'â—','å·®ã—':'â–³','è¿½è¾¼':'Ã—'},
    'ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹':{'é€ƒã’':'â—','å…ˆè¡Œ':'ã€‡','å·®ã—':'â–³','è¿½è¾¼':'Ã—'},
}
mark_to_pts={'â—':2,'ã€‡':1,'â—‹':1,'â–³':0,'Ã—':-1}
rng_pace=np.random.default_rng(int(mc_seed)+12345)
sum_pts=np.zeros(H); pace_counter={'ãƒã‚¤ãƒšãƒ¼ã‚¹':0,'ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹':0,'ã‚„ã‚„ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹':0,'ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹':0}
for _ in range(int(pace_mc_draws)):
    sampled=[rng_pace.choice(4, p=P[i]/P[i].sum() if P[i].sum()>0 else np.array([.25,.25,.25,.25])) for i in range(H)]
    nige=sum(1 for s in sampled if s==0); sengo=sum(1 for s in sampled if s==1)
    epi=(epi_alpha*nige + epi_beta*sengo)/max(1,H)
    pace_t="ãƒã‚¤ãƒšãƒ¼ã‚¹" if epi>=thr_hi else "ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹" if epi>=thr_mid else "ã‚„ã‚„ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" if epi>=thr_slow else "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹"
    pace_counter[pace_t]+=1; mk=mark_rule[pace_t]
    for i,s in enumerate(sampled): sum_pts[i]+=mark_to_pts[ mk[STYLES[s]] ]
df_agg['PacePts']=sum_pts/max(1,int(pace_mc_draws))
pace_type=max(pace_counter,key=lambda k: pace_counter[k]) if sum(pace_counter.values())>0 else "ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹"
if pace_mode=="å›ºå®šï¼ˆæ‰‹å‹•ï¼‰":
    pace_type=pace_fixed
    v_pts=np.array([mark_to_pts[mark_rule[pace_type][st]] for st in STYLES])
    df_agg['PacePts']=P@v_pts

df_agg['FinalRaw']=df_agg['RecencyZ'] + stab_weight*df_agg['StabZ'] + pace_gain*df_agg['PacePts']
df_agg['FinalZ']=z_score(df_agg['FinalRaw']) if (df_agg['FinalRaw'].max()-df_agg['FinalRaw'].min())>1e-9 \
                 else 50 + (df_agg['WAvgZ']-df_agg['WAvgZ'].mean())*0.1

# ===== æ•£å¸ƒå›³ï¼ˆç¸¦è»¸ã®è¦‹ãˆæ–¹ã‚’å®‰å®šåŒ–ï¼‰ =====
if ALT_AVAILABLE and not df_agg.empty:
    x_min,float_x_max = float(df_agg['FinalZ'].min()), float(df_agg['FinalZ'].max())
    y_min_raw,y_max_raw = float(df_agg['WStd'].min()), float(df_agg['WStd'].max())
    y_lo = max(0.0, y_min_raw - 0.5)
    y_hi = y_max_raw + 0.5
    quad_rect = pd.DataFrame([
        {'x1': x_min, 'x2': 50.0, 'y1': (y_lo+y_hi)/2, 'y2': y_hi},
        {'x1': 50.0, 'x2': float_x_max, 'y1': (y_lo+y_hi)/2, 'y2': y_hi},
        {'x1': x_min, 'x2': 50.0, 'y1': y_lo, 'y2': (y_lo+y_hi)/2},
        {'x1': 50.0, 'x2': float_x_max, 'y1': y_lo, 'y2': (y_lo+y_hi)/2},
    ])
    rect = alt.Chart(quad_rect).mark_rect(opacity=0.07).encode(
        x='x1:Q', x2='x2:Q', y='y1:Q', y2='y2:Q')
    points = alt.Chart(df_agg).mark_circle(size=100).encode(
        x=alt.X('FinalZ:Q', title='æœ€çµ‚åå·®å€¤',
                scale=alt.Scale(domain=(x_min-1, float_x_max+1), nice=False)),
        y=alt.Y('WStd:Q', title='åŠ é‡æ¨™æº–åå·®ï¼ˆå°ã•ã„ã»ã©å®‰å®šï¼‰',
                scale=alt.Scale(domain=(y_lo, y_hi), nice=True, clamp=True),
                axis=alt.Axis(format='.1f')),
        tooltip=['é¦¬å','WAvgZ','WStd','RecencyZ','StabZ','PacePts','FinalZ']
    )
    labels = alt.Chart(df_agg).mark_text(dx=6, dy=-6, fontSize=10, color='#ffffff').encode(
        x='FinalZ:Q', y='WStd:Q', text='é¦¬å:N'
    )
    vline = alt.Chart(pd.DataFrame({'x':[50.0]})).mark_rule(color='gray').encode(x='x:Q')
    hline = alt.Chart(pd.DataFrame({'y':[(y_lo+y_hi)/2]})).mark_rule(color='gray').encode(y='y:Q')
    quad_text = alt.Chart(pd.DataFrame([
        {'label':'æ¶ˆã—ãƒ»å¤§ç©´',   'x': (x_min+50)/2,       'y': (y_lo+y_hi*1.0)/2},
        {'label':'æ³¢ä¹±ãƒ»ãƒ ãƒ©é¦¬', 'x': (50+float_x_max)/2, 'y': (y_lo+y_hi*1.0)/2},
        {'label':'å …å®Ÿãƒ’ãƒ¢',     'x': (x_min+50)/2,       'y': (y_lo+(y_lo+y_hi)/2)/2},
        {'label':'é‰„æ¿ãƒ»æœ¬å‘½',   'x': (50+float_x_max)/2, 'y': (y_lo+(y_lo+y_hi)/2)/2},
    ])).mark_text(fontSize=14, fontWeight='bold', color='#ffffff').encode(x='x:Q', y='y:Q', text='label:N')
    st.altair_chart((rect+points+labels+vline+hline+quad_text).properties(height=420), use_container_width=True)

# ===== å‹ç‡MCï¼ˆå…ˆã«è¨ˆç®—ï¼‰ =====
S=df_agg['FinalRaw'].to_numpy(float)
S=(S-np.nanmean(S))/(np.nanstd(S)+1e-9)
W=df_agg['WStd'].fillna(df_agg['WStd'].median()).to_numpy(float)
W=(W-W.min())/(W.max()-W.min()+1e-9)
n=len(S); rng=np.random.default_rng(int(mc_seed))
gumbel=rng.gumbel(0.0,1.0,size=(mc_iters,n))
noise=(mc_tau*W)[None,:]*rng.standard_normal((mc_iters,n))
U=mc_beta*S[None,:]+noise+gumbel
rank_idx=np.argsort(-U,axis=1)
win_counts=np.bincount(rank_idx[:,0], minlength=n).astype(float)
top3_counts=np.zeros(n); 
for k in range(3): top3_counts += np.bincount(rank_idx[:,k], minlength=n).astype(float)
df_agg['å‹ç‡%_MC']=(win_counts/mc_iters*100).round(2)
df_agg['è¤‡å‹ç‡%_MC']=(top3_counts/mc_iters*100).round(2)
prob_view=(df_agg[['é¦¬å','FinalZ','WAvgZ','WStd','PacePts','å‹ç‡%_MC','è¤‡å‹ç‡%_MC']]
           .sort_values('å‹ç‡%_MC',ascending=False).reset_index(drop=True))

# ===== ä¸Šä½é¦¬ =====
CUTOFF=50.0
topN=df_agg[df_agg['FinalZ']>=CUTOFF].sort_values('FinalZ',ascending=False).head(6).copy()
topN['å°']=['â—','ã€‡','â–²','â˜†','â–³','â–³'][:len(topN)]

# ===== å±•é–‹è¡¨ç”¨ =====
def _normalize_ban(x): return pd.to_numeric(str(x).translate(str.maketrans('ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™','0123456789')), errors='coerce')
df_map=horses.copy(); df_map['è„šè³ª']=df_map['é¦¬å'].map(combined_style).fillna(df_map.get('è„šè³ª',''))
df_map['ç•ª']=_normalize_ban(df_map['ç•ª']); df_map=df_map.dropna(subset=['ç•ª']).astype({'ç•ª':int})
df_map['è„šè³ª']=pd.Categorical(df_map['è„šè³ª'], categories=STYLES, ordered=True)

# ===== horses2ï¼ˆçŸ­è©•ï¼‰ =====
å°map = dict(zip(topN['é¦¬å'], topN['å°']))

# df_agg ãŒç©ºã§ã‚‚è½ã¡ãªã„ã‚ˆã†ã«ã€ã‚ã‚‹åˆ—ã ã‘å–ã‚‹
merge_cols = [c for c in ['é¦¬å','WAvgZ','WStd','FinalZ','è„šè³ª','PacePts'] if c in df_agg.columns]
horses2 = horses.merge(df_agg[merge_cols], on='é¦¬å', how='left') if merge_cols else horses.copy()

# æ¬ æã‚¬ãƒ¼ãƒ‰ï¼šå¿…è¦åˆ—ã‚’å¿…ãšä½œã‚‹ï¼ˆKeyErrorå¯¾ç­–ï¼‰
for col, default in [('å°',''), ('è„šè³ª',''), ('çŸ­è©•',''), ('WAvgZ', np.nan), ('WStd', np.nan), ('FinalZ', np.nan), ('PacePts', np.nan)]:
    if col not in horses2.columns:
        horses2[col] = default

# å°ã®ä»˜ä¸
horses2['å°'] = horses2['é¦¬å'].map(å°map).fillna('')

def ai_comment(row):
    base = ""
    if row['å°'] == 'â—':
        base += "æœ¬å‘½è©•ä¾¡ã€‚" + ("é«˜ã„å®‰å®šæ„Ÿã§ä¿¡é ¼åº¦æŠœç¾¤ã€‚" if pd.notna(row['WStd']) and row['WStd'] <= 8 else "èƒ½åŠ›ä¸Šä½ã‚‚ãƒ ãƒ©ã‚ã‚Šã€‚")
    elif row['å°'] == 'ã€‡':
        base += "å¯¾æŠ—è©•ä¾¡ã€‚" + ("è¿‘èµ°å®‰å®šã—ã¦ãŠã‚Šè»¸å€™è£œã€‚" if pd.notna(row['WStd']) and row['WStd'] <= 10 else "å±•é–‹ã²ã¨ã¤ã§é€†è»¢ã‚‚ã€‚")
    elif row['å°'] in ['â–²','â˜†']:
        base += "ä¸Šä½ã‚°ãƒ«ãƒ¼ãƒ—ã®ä¸€è§’ã€‚" + ("ãƒ ãƒ©ãŒã‚ã‚Šä¸€ç™ºã‚¿ã‚¤ãƒ—ã€‚" if pd.notna(row['WStd']) and row['WStd'] > 15 else "å®‰å®šå‹ã§å …å®Ÿã€‚")
    elif row['å°'] == 'â–³':
        base += "æŠ¼ã•ãˆå€™è£œã€‚" + ("å …å®Ÿã ãŒå‹ã¡åˆ‡ã‚‹ã¾ã§ã¯ï¼Ÿ" if pd.notna(row['WStd']) and row['WStd'] < 12 else "å±•é–‹æ¬¡ç¬¬ã§æµ®ä¸Šã‚‚ã€‚")
    style = str(row.get('è„šè³ª','')).strip()
    base += {
        "é€ƒã’":"ãƒãƒŠã‚’å¥ªãˆã‚Œã°ç²˜ã‚Šè¾¼ã¿ååˆ†ã€‚",
        "å…ˆè¡Œ":"å…ˆè¡ŒåŠ›ã‚’æ´»ã‹ã—ã¦ä¸Šä½äº‰ã„ã€‚",
        "å·®ã—":"å±•é–‹ãŒå‘ã‘ã°æœ«è„šå¼·çƒˆã€‚",
        "è¿½è¾¼":"ç›´ç·šå‹è² ã®ä¸€æ’ƒã«æœŸå¾…ã€‚"
    }.get(style, "")
    return base

# çŸ­è©•ï¼ˆå®‰å…¨ã«ç”Ÿæˆï¼‰
try:
    horses2['çŸ­è©•'] = horses2.apply(ai_comment, axis=1)
except Exception:
    # ä½•ã‹ã‚ã£ã¦ã‚‚è½ã¨ã•ãªã„
    if 'çŸ­è©•' not in horses2:
        horses2['çŸ­è©•'] = ""


# ===== è³‡é‡‘é…åˆ†ãƒ»è²·ã„ç›® =====
st.subheader("â–  è³‡é‡‘é…åˆ† (å³å¯†åˆè¨ˆ)")
main_share=0.5
def round_to_unit(x,unit): return int(np.floor(x/unit)*unit)
pur1=round_to_unit(total_budget*main_share*(1/4), int(min_unit))
pur2=round_to_unit(total_budget*main_share*(3/4), int(min_unit))
rem=total_budget-(pur1+pur2)
win_each=round_to_unit(pur1/2, int(min_unit)); place_each=round_to_unit(pur2/2, int(min_unit))
st.write(f"åˆè¨ˆäºˆç®—ï¼š{total_budget:,}å††  å˜å‹ï¼š{pur1:,}å††  è¤‡å‹ï¼š{pur2:,}å††  æ®‹ï¼š{rem:,}å††  [å˜ä½:{min_unit}å††]")

h1=topN.iloc[0]['é¦¬å'] if len(topN)>=1 else None
h2=topN.iloc[1]['é¦¬å'] if len(topN)>=2 else None
bets=[]
if h1: bets += [{'åˆ¸ç¨®':'å˜å‹','å°':'â—','é¦¬':h1,'ç›¸æ‰‹':'','é‡‘é¡':win_each},
                {'åˆ¸ç¨®':'è¤‡å‹','å°':'â—','é¦¬':h1,'ç›¸æ‰‹':'','é‡‘é¡':place_each}]
if h2: bets += [{'åˆ¸ç¨®':'å˜å‹','å°':'ã€‡','é¦¬':h2,'ç›¸æ‰‹':'','é‡‘é¡':win_each},
                {'åˆ¸ç¨®':'è¤‡å‹','å°':'ã€‡','é¦¬':h2,'ç›¸æ‰‹':'','é‡‘é¡':place_each}]

finalZ_map=df_agg.set_index('é¦¬å')['FinalZ'].to_dict()
names=topN['é¦¬å'].tolist(); symbols=topN['å°'].tolist()
others=names[1:]; others_sym=symbols[1:]
pair_candidates=[]; tri_candidates=[]; tri1_candidates=[]
if h1 and others:
    for nm,mk in zip(others,others_sym):
        score=finalZ_map.get(nm,0)
        pair_candidates += [('ãƒ¯ã‚¤ãƒ‰', f'â—â€“{mk}', h1, nm, score),
                            ('é¦¬é€£' , f'â—â€“{mk}', h1, nm, score),
                            ('é¦¬å˜' , f'â—â†’{mk}', h1, nm, score)]
    from itertools import combinations as comb
    for a,b in comb(others,2):
        tri_candidates.append(('ä¸‰é€£è¤‡','â—-ã€‡â–²â˜†â–³â–³', h1, f"{a}ï¼{b}", finalZ_map.get(a,0)+finalZ_map.get(b,0)))
    second_opts=others[:2]
    for s in second_opts:
        for t in others:
            if t==s: continue
            tri1_candidates.append(('ä¸‰é€£å˜ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³','â—-ã€‡â–²-ã€‡â–²â˜†â–³â–³', h1, f"{s}ï¼{t}", finalZ_map.get(s,0)+0.7*finalZ_map.get(t,0)))

three=['é¦¬é€£','ãƒ¯ã‚¤ãƒ‰','é¦¬å˜']
if scenario=='é€šå¸¸':
    with st.expander("é¦¬é€£ãƒ»ãƒ¯ã‚¤ãƒ‰ãƒ»é¦¬å˜ ã‹ã‚‰ï¼‘åˆ¸ç¨®ã‚’é¸æŠ", expanded=True):
        choice=st.radio("è³¼å…¥åˆ¸ç¨®", options=three, index=1, horizontal=True)
        st.write(f"â–¶ {choice} ã«æ®‹ã‚Š {rem:,}å†† ã‚’å……å½“")
    cand=[c for c in pair_candidates if c[0]==choice]
    cand=sorted(cand,key=lambda x:x[-1],reverse=True)[:int(max_lines)]
    K=len(cand)
    if K>0 and rem>=int(min_unit):
        base=round_to_unit(rem/K, int(min_unit)); amts=[base]*K; leftover=rem-base*K; i=0
        while leftover>=int(min_unit) and i<K: amts[i]+=int(min_unit); leftover-=int(min_unit); i+=1
        for (typ,mks,bh,ph,_),amt in zip(cand,amts): bets.append({'åˆ¸ç¨®':typ,'å°':mks,'é¦¬':bh,'ç›¸æ‰‹':ph,'é‡‘é¡':int(amt)})
elif scenario=='ã¡ã‚‡ã„ä½™è£•':
    cand_wide=sorted([c for c in pair_candidates if c[0]=='ãƒ¯ã‚¤ãƒ‰'], key=lambda x:x[-1], reverse=True)
    cand_tri =sorted(tri_candidates, key=lambda x:x[-1], reverse=True)
    cut_w=min(len(cand_wide), int(max_lines)//2 if int(max_lines)>1 else 1)
    cut_t=min(len(cand_tri), int(max_lines)-cut_w)
    allc=cand_wide[:cut_w]+cand_tri[:cut_t]
    K=len(allc)
    if K>0 and rem>=int(min_unit):
        base=round_to_unit(rem/K, int(min_unit)); amts=[base]*K; leftover=rem-base*K; i=0
        while leftover>=int(min_unit) and i<K: amts[i]+=int(min_unit); leftover-=int(min_unit); i+=1
        for (typ,mks,bh,ph,_),amt in zip(allc,amts): bets.append({'åˆ¸ç¨®':typ,'å°':mks,'é¦¬':bh,'ç›¸æ‰‹':ph,'é‡‘é¡':int(amt)})
elif scenario=='ä½™è£•':
    cand_wide=sorted([c for c in pair_candidates if c[0]=='ãƒ¯ã‚¤ãƒ‰'], key=lambda x:x[-1], reverse=True)
    cand_tri =sorted(tri_candidates, key=lambda x:x[-1], reverse=True)
    cand_tri1=sorted(tri1_candidates, key=lambda x:x[-1], reverse=True)
    r_w,r_t,r_t1=2,2,1; denom=r_w+r_t+r_t1
    q_w=max(1,(int(max_lines)*r_w)//denom); q_t=max(1,(int(max_lines)*r_t)//denom); q_t1=max(1,int(max_lines)-q_w-q_t)
    allc=cand_wide[:q_w]+cand_tri[:q_t]+cand_tri1[:q_t1]; K=len(allc)
    if K>0 and rem>=int(min_unit):
        base=round_to_unit(rem/K, int(min_unit)); amts=[base]*K; leftover=rem-base*K; i=0
        while leftover>=int(min_unit) and i<K: amts[i]+=int(min_unit); leftover-=int(min_unit); i+=1
        for (typ,mks,bh,ph,_),amt in zip(allc,amts): bets.append({'åˆ¸ç¨®':typ,'å°':mks,'é¦¬':bh,'ç›¸æ‰‹':ph,'é‡‘é¡':int(amt)})

_df=pd.DataFrame(bets)
spent=int(_df['é‡‘é¡'].fillna(0).replace('',0).sum()) if len(_df)>0 else 0
diff=total_budget-spent
if diff!=0 and len(_df)>0:
    for idx in _df.index:
        cur=int(_df.at[idx,'é‡‘é¡']); new=cur+diff
        if new>=0 and new%int(min_unit)==0: _df.at[idx,'é‡‘é¡']=new; break
_df_disp=_df.copy()
if 'é‡‘é¡' in _df_disp and len(_df_disp)>0:
    _df_disp['é‡‘é¡']=_df_disp['é‡‘é¡'].map(lambda x: "" if (pd.isna(x) or int(x)<=0) else f"{int(x):,}å††")

# ===== ã‚¿ãƒ– =====
tab_dash, tab_prob, tab_pace, tab_bets, tab_all = st.tabs(["ğŸ  ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰","ğŸ“ˆ å‹ç‡","ğŸ§­ å±•é–‹","ğŸ« è²·ã„ç›®","ğŸ“ å…¨é ­ã‚³ãƒ¡ãƒ³ãƒˆ"])

with tab_dash:
    st.subheader("ã‚µãƒãƒªãƒ¼")
    c1,c2,c3,c4=st.columns(4)
    c1.metric("æƒ³å®šãƒšãƒ¼ã‚¹", locals().get("pace_type","â€”"))
    c2.metric("å‡ºèµ°é ­æ•°", len(horses))
    if len(topN)>0:
        c3.metric("â— FinalZ", f"{topN.iloc[0]['FinalZ']:.1f}")
        try:
            win_pct=float(prob_view.loc[prob_view['é¦¬å']==topN.iloc[0]['é¦¬å'],'å‹ç‡%_MC'].iloc[0])
            c4.metric("â— æ¨å®šå‹ç‡", f"{win_pct:.1f}%")
        except Exception: c4.metric("â— æ¨å®šå‹ç‡", "â€”")
    st.markdown("#### ä¸Šä½é¦¬ï¼ˆFinalZâ‰§50ãƒ»æœ€å¤§6é ­ï¼‰")
    if len(topN)==0:
        st.info("è©²å½“ãªã—")
    else:
        cols=[c for c in ['é¦¬å','å°','FinalZ','WAvgZ','WStd','PacePts','å‹ç‡%_MC'] if c in topN.columns]
        _top_view=topN[cols].copy()
        st.dataframe(_top_view, use_container_width=True, height=240)
        st.download_button("â¬‡ ä¸Šä½é¦¬CSV", data=_top_view.to_csv(index=False).encode("utf-8-sig"), file_name="topN.csv", mime="text/csv")

with tab_prob:
    st.subheader("æ¨å®šå‹ç‡ãƒ»è¤‡å‹ç‡ï¼ˆãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ï¼‰")
    _pv=prob_view.copy()
    for c in ['å‹ç‡%_MC','è¤‡å‹ç‡%_MC']:
        if c in _pv: _pv[c]=_pv[c].map(lambda x: f"{x:.2f}%")
    st.dataframe(_pv, use_container_width=True, height=380)
    st.download_button("â¬‡ å‹ç‡ãƒ†ãƒ¼ãƒ–ãƒ«CSV", data=prob_view.to_csv(index=False).encode("utf-8-sig"), file_name="probability_table.csv", mime="text/csv")

with tab_pace:
    st.subheader("å±•é–‹ãƒ»è„šè³ªã‚µãƒãƒªãƒ¼")
    st.caption(f"æƒ³å®šãƒšãƒ¼ã‚¹: {locals().get('pace_type','â€”')}ï¼ˆ{'å›ºå®š' if st.session_state.get('pace_mode')=='å›ºå®šï¼ˆæ‰‹å‹•ï¼‰' else 'è‡ªå‹•MC'}ï¼‰")
    _sc=df_map['è„šè³ª'].value_counts().reindex(STYLES).fillna(0).astype(int)
    st.table(pd.DataFrame(_sc, columns=['é ­æ•°']).T)

with tab_bets:
    st.subheader("æœ€çµ‚è²·ã„ç›®ä¸€è¦§")
    if _df_disp.empty:
        st.info("ç¾åœ¨ã€è²·ã„ç›®ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        show=[c for c in ['åˆ¸ç¨®','å°','é¦¬','ç›¸æ‰‹','é‡‘é¡'] if c in _df_disp.columns]
        st.dataframe(_df_disp[show], use_container_width=True, height=320)
        st.download_button("â¬‡ è²·ã„ç›®CSV", data=_df_disp[show].to_csv(index=False).encode("utf-8-sig"), file_name="bets.csv", mime="text/csv")

with tab_all:
    st.subheader("å…¨é ­AIè¨ºæ–­ã‚³ãƒ¡ãƒ³ãƒˆ")
    q = st.text_input("é¦¬åãƒ•ã‚£ãƒ«ã‚¿ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰", "")

    # â† å®‰å…¨ãªåˆ—é¸æŠï¼ˆå­˜åœ¨ã™ã‚‹åˆ—ã ã‘ï¼‰
    show_cols = [c for c in ['é¦¬å','å°','è„šè³ª','çŸ­è©•','WAvgZ','WStd'] if c in horses2.columns]
    _all = horses2[show_cols].copy()

    if q.strip():
        _all = _all[_all['é¦¬å'].astype(str).str.contains(q.strip(), case=False, na=False)]

    if _all.empty:
        st.info("ã‚³ãƒ¡ãƒ³ãƒˆè¡¨ç¤ºå¯¾è±¡ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¸Šéƒ¨ã®å…¥åŠ›ã¨è¨ˆç®—çµæœã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
    else:
        st.dataframe(_all, use_container_width=True, height=420)
        st.download_button("â¬‡ å…¨é ­ã‚³ãƒ¡ãƒ³ãƒˆCSV",
            data=_all.to_csv(index=False).encode("utf-8-sig"),
            file_name="all_comments.csv", mime="text/csv")
